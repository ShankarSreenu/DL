{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26169674413617655\n",
      "90.31645569620254\n",
      "88.65979381443299\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "\n",
    "#loads the dataset if you input:directory\n",
    "def load_dataset(folder):\n",
    "    images = []\n",
    "    y=[]\n",
    "    limit=0\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            temp=filename.split(\".\")\n",
    "            y.append(int(temp[0][-1]))\n",
    "    return np.array(images),np.array(y)\n",
    "\n",
    "class neural_network_class:\n",
    "    def __init__(self,layers,X,Y):\n",
    "        self.X=X #input \n",
    "        self.Y=Y  #classes\n",
    "        self.m=X.shape[1] #shape of X\n",
    "        self.y_n=len(np.unique(Y)) #no of classes\n",
    "        self.no_of_layers=len(layers) # no of layers\n",
    "        self.parameters={}  #stores W,b,Z,A\n",
    "        self.d={}   #stores partial derivatives\n",
    "        self.parameters[\"A0\"]=X #X input can be considered as A0\n",
    "        layers.append(self.y_n) #appending last layer \n",
    "        \n",
    "        #initialising the parameters weights bias,activation for l layers\n",
    "        \n",
    "\n",
    "        for l in range(0,len(layers)-1):\n",
    "            self.parameters[\"W\"+str(l+1)]=np.random.randn(layers[l+1],layers[l])*0.01\n",
    "            self.parameters[\"b\"+str(l+1)]=np.zeros((layers[l+1],1))\n",
    "            self.parameters[\"Z\"+str(l+1)]=None\n",
    "            self.parameters[\"A\"+str(l+1)]=None\n",
    "        \n",
    "        #initialising dZ,dW,db,dA values for l layers\n",
    "        for l in range(0,len(layers)-1):\n",
    "            self.d[\"Z\"+str(l+1)]=None\n",
    "            self.d[\"W\"+str(l+1)]=None\n",
    "            self.d[\"b\"+str(l+1)]=None\n",
    "            \n",
    "    #soft max_function\n",
    "    #exp(Z1)/sum(exp(Z1))\n",
    "    def softmax(self):\n",
    "        A=self.parameters[\"Z\"+str(self.no_of_layers)]\n",
    "        return np.exp(A)/np.sum(np.exp(A),axis=0,keepdims=True)\n",
    "    \n",
    "    \n",
    "    #one hat encoding\n",
    "    #example [0,1,2]\n",
    "    #ouput \n",
    "    #[1,0,0]\n",
    "    #[0,1,0]\n",
    "    #[0,0,1]\n",
    "    \n",
    "    def one_hat_encode(self,Y):\n",
    "        y_h=np.zeros((Y.shape[0],self.y_n))\n",
    "        for i in range(0,X.shape[1]):\n",
    "            y_h[i][Y[i]]=1\n",
    "        self.y_h=y_h.T\n",
    "\n",
    "            \n",
    "    def feedforward(self):\n",
    "        for l in range(0,self.no_of_layers-1):\n",
    "            W,b=self.parameters[\"W\"+str(l+1)],self.parameters[\"b\"+str(l+1)]\n",
    "            A_prev=self.parameters[\"A\"+str(l)]\n",
    "            Z=np.dot(W,A_prev)+b\n",
    "            self.parameters[\"Z\"+str(l+1)]=Z\n",
    "            self.parameters[\"A\"+str(l+1)]=self.Activation(Z,\"sigmoid\")\n",
    "        \n",
    "        #soft max layer\n",
    "        W,b=self.parameters[\"W\"+str(self.no_of_layers)],self.parameters[\"b\"+str(self.no_of_layers)]\n",
    "        Aprev=self.parameters[\"A\"+str(self.no_of_layers-1)]\n",
    "        self.parameters[\"Z\"+str(self.no_of_layers)]=np.dot(W,Aprev)+b\n",
    "        self.parameters[\"A\"+str(self.no_of_layers)]=self.softmax()\n",
    "        \n",
    "    #activation function       \n",
    "    def Activation(self,Z,arg):\n",
    "        if arg==\"sigmoid\":\n",
    "            return 1/(1+np.exp(-Z))\n",
    "        if arg==\"relu\":\n",
    "            return np.maximum(0,Z)\n",
    "        \n",
    "    #calucualate the loss\n",
    "    #sigma sigma -plogq multi class cross entropy \n",
    "    def cost(self):\n",
    "        A=self.softmax()\n",
    "        self.loss=(-1/self.m)*np.sum(np.multiply(self.y_h,np.log(A)))\n",
    "        print(self.loss)\n",
    "    \n",
    "    # dervative of sigmoid g(x)(1-g(x))\n",
    "    def gx(self,x):\n",
    "        return np.multiply(x,1-x)\n",
    "        \n",
    "    #back propagation step\n",
    "    def backprop(self):\n",
    "        l=self.no_of_layers\n",
    "        P = self.parameters[\"A\"+str(l)]\n",
    "        A_prev=self.parameters[\"A\"+str(l-1)]\n",
    "        \n",
    "        #softmax layer\n",
    "        #partial derivate cost fun\n",
    "        #predicted P probabities from softmax\n",
    "        #y_h ground truth\n",
    "        dZ = (1/self.m)*(P- self.y_h)\n",
    "        dW=np.dot(dZ,A_prev.T)\n",
    "        db=np.sum(dZ,axis=1,keepdims=True)\n",
    "        \n",
    "        self.d[\"Z\"+str(l)]=dZ\n",
    "        self.d[\"W\"+str(l)]=dW\n",
    "        self.d[\"b\"+str(l)]=db\n",
    "        \n",
    "        for i in range(0,l-1):\n",
    "            \n",
    "            A_prev =   self.parameters[\"A\"+str(l-i-1)]\n",
    "            W      =  self.parameters[\"W\"+str(l-i)]\n",
    "            dZ_prev=  self.d[\"Z\"+str(l-i)]\n",
    "            \n",
    "            \n",
    "            dZ     =  np.multiply(np.dot(W.T,dZ_prev),self.gx(A_prev))\n",
    "            A      =  self.parameters[\"A\"+str(l-i-2)]\n",
    "            dW     =  np.dot(dZ,A.T)\n",
    "            db     =  np.sum(dZ,axis=1,keepdims=True)\n",
    "            #print(dZ)\n",
    "            self.d[\"Z\"+str(l-i-1)]=dZ\n",
    "            self.d[\"W\"+str(l-i-1)]=dW\n",
    "            self.d[\"b\"+str(l-i-1)]=db\n",
    "            \n",
    "    #update weights\n",
    "    #W=W-n*dW\n",
    "    #b=b-n*db\n",
    "    def upgrade(self):\n",
    "        for l in range(0,self.no_of_layers):\n",
    "            self.parameters[\"W\"+str(l+1)]=self.parameters[\"W\"+str(l+1)]-0.1*self.d[\"W\"+str(l+1)]\n",
    "            self.parameters[\"b\"+str(l+1)]=self.parameters[\"b\"+str(l+1)]-0.1*self.d[\"b\"+str(l+1)]\n",
    "        \n",
    "    #train the model\n",
    "    def train(self,epochs):\n",
    "        for i in range(0,epochs):\n",
    "            network.feedforward()\n",
    "            network.backprop()\n",
    "            network.upgrade()\n",
    "        network.cost()\n",
    "        \n",
    "    #caluculates the accuracy \n",
    "    def Accuaracy(self):\n",
    "        i=0\n",
    "        acc=0\n",
    "        prob=self.parameters[\"A\"+str(self.no_of_layers)].T\n",
    "        for val in self.y_h:\n",
    "            if np.argmax(val)==np.argmax(prob[i]):\n",
    "                acc=acc+1\n",
    "            i=i+1\n",
    "        print((acc/i)*100)\n",
    "        \n",
    "    def test(self):\n",
    "        prediction=self.parameters[\"A\"+str(self.no_of_layers)].T\n",
    "        y_sample=self.y_h.T\n",
    "        flattened_labels = np.argmax(y_sample, axis=1) \n",
    "        flattened_prediction = np.argmax(prediction, axis=1)\n",
    "        assert flattened_labels.shape == flattened_prediction.shape\n",
    "        return np.mean(flattened_labels == flattened_prediction)*100\n",
    "    \n",
    "    def test_dataset(self,X,Y):\n",
    "        self.parameters[\"A0\"]=X\n",
    "        self.one_hat_encode(Y)\n",
    "        self.feedforward()\n",
    "        print(self.test())\n",
    "    \n",
    "        \n",
    "X,y=load_dataset(\"/home/shanky/btp/datset/final_train\")\n",
    "Y=np.array(y)\n",
    "X_flatten = X.reshape(X.shape[0], -1).T\n",
    "X=X_flatten/255     \n",
    "\n",
    "        \n",
    "\n",
    "layers=[X.shape[0],250,150]\n",
    "network=neural_network_class(layers,X,Y)\n",
    "network.one_hat_encode(Y)\n",
    "network.train(1000)\n",
    "\n",
    "print(network.test())\n",
    "X,y=load_dataset(\"/home/shanky/btp/datset/final_test\")\n",
    "Y=np.array(y)\n",
    "X_flatten = X.reshape(X.shape[0], -1).T\n",
    "X=X_flatten/255\n",
    "network.test_dataset(X,Y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X=np.array([[1,1],[1,0],[0,1],[0,0]]).T    \n",
    "Y=np.array([0,1,2,0])\n",
    "y_h=np.zeros((Y.shape[0],3))\n",
    "for i in range(0,X.shape[1]):\n",
    "    y_h[i][Y[i]]=1\n",
    "y_h=y_h.T\n",
    "print(y_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "train = pd.read_csv(\"training1.csv\")\n",
    "X = train.iloc[:,:-1].values.T\n",
    "Y = train.iloc[:,-1].values\n",
    "#X=np.array([[1,1],[1,0],[0,1],[0,0]]).T    \n",
    "#Y=np.array([0,1,1,0]) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /home/shanky/.local/lib/python3.8/site-packages (2.3.1)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /home/shanky/.local/lib/python3.8/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /home/shanky/.local/lib/python3.8/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.35.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.18.4)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /home/shanky/.local/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /home/shanky/.local/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/lib/python3/dist-packages (from tensorflow) (3.12.3)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/shanky/.local/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /home/shanky/.local/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /home/shanky/.local/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /home/shanky/.local/lib/python3.8/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/shanky/.local/lib/python3.8/site-packages (from tensorflow) (0.11.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/shanky/.local/lib/python3.8/site-packages (from tensorflow) (1.34.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/shanky/.local/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/shanky/.local/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/lib/python3/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/lib/python3/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (46.1.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/shanky/.local/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.23.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/shanky/.local/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.23.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/shanky/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/shanky/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /home/shanky/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/shanky/.local/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.2)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
